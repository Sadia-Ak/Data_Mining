{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89580a51-b48c-41cc-95e6-134f7ef9b968",
   "metadata": {},
   "source": [
    "# Homework Assignment 5: Data Prep\n",
    "In this homework assignment, you will continue your exploration of the [SWAN-SF Dataset](https://doi.org/10.7910/DVN/EBCFKM), described in the paper found [here](https://doi.org/10.1038/s41597-020-0548-x).\n",
    "\n",
    "\n",
    "This assignment will have you explore the cardinalities, number of missing values, detect outliers, handle missing values and outliers, and create data quality report for original and cleaned dataset. Additionally, you will be asked to provide documentation for your functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c64882-0cac-4dd6-a941-64b1694392e4",
   "metadata": {},
   "source": [
    "## Step 1: Downloading the Data\n",
    "\n",
    "This assignment will only be using [Partition 1](https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/EBCFKM/BMXYCB). Recall that in Homework 4 we started to construct the analytics base table for our [SWAN-SF Dataset](https://doi.org/10.7910/DVN/EBCFKM). In that assignment, we read the data from one of the two subdirectories, __FL__ and __NF__, of the __partition1__ directory. These two subdirectories represented the two classes of our target feature in a solar flare prediction problem, and you were asked to extract the flare class of a sample. For this assignment, I have processed these samples of multivariate time series to construct descriptive features for each sample, and then placed them into an analytics base table.\n",
    "\n",
    "In this assignment, you will be utilizing a set of extracted descriptive features. This dataset contains many extracted features for each multi variate time series instance (>800), so we need to explore the data to find data quality issues and identify ways to address these issues. Below are links to the full extracted feature dataset for partition 1 and a toy dataset to use for testing your functions. __Note:__ Since the full dataset, and multiple copies of partially processed intermediary results, tend to take up a bit of space, you can use the toy dataset to implement and test your code. You may need to edit the data to fully test each of the requirements, but that is left as an exercise for the student. The full partition dataset is only included for those who wish to work with it once they have their code implemented. \n",
    "\n",
    "- [Full Partition 1 feature dataset](http://dmlab.cs.gsu.edu/solar/data/partition1ExtractedFeatures.csv)\n",
    "- [Toy Partition 1 feature dataset](http://dmlab.cs.gsu.edu/solar/data/toy_partition1ExtractedFeatures.csv)\n",
    "\n",
    "Now that you have the extracted features csv files, you will load that data into a Spark DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d89f7-6093-419a-8083-f0f4f1e5aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0e7e51-f757-44f3-9c49-b9ff9991f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master(\"spark://127.0.0.1:7077\")\n",
    "    # the number of executors this job needs\n",
    "    .config(\"spark.executor.instances\", 2)\n",
    "    # the number of CPU cores memory this needs from the executor,\n",
    "    # it would be reserved on the worker\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    .config(\"spark.executor.memory\", \"4G\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1bfdd-e6cc-49ef-a7ec-36f87c826106",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/MVTS'\n",
    "#data_dir = './'\n",
    "data_file = 'toy_partition1ExtractedFeatures.csv'\n",
    "#data_file = 'partition1ExtractedFeatures.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3b628-21b2-497e-bfa2-f0cfb3502434",
   "metadata": {},
   "outputs": [],
   "source": [
    "abt = (spark.read.format(\"csv\").option(\"inferSchema\", \"true\")\n",
    "       .option(\"sep\", \",\").option(\"lineSep\", \"\\n\")\n",
    "       .option(\"header\", \"true\")\n",
    "       .load(os.path.join(data_dir, data_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad5e9e-d6a0-4175-850c-272830da6453",
   "metadata": {},
   "source": [
    "### Q1 (20 points)\n",
    "\n",
    "Write a function to extract the various pieces of a data quality report, for a specific attribute, and return a pandas DataFrame with this information.\n",
    "\n",
    " * 'Feature Name': Contains the time series statistical feature name\n",
    " \n",
    " * 'Cardinality': Contains the count of unique values for the feature\n",
    "            \n",
    " * 'Non-null Count': Contains the number of non-null entries for the feature\n",
    "            \n",
    " * 'Null Count': Contains the number of null or missing entries for the feature\n",
    "            \n",
    " * 'Min': Contains the minimum value of the feature\n",
    " \n",
    " * '25th': Contains the first quartile (25%) of the feature values\n",
    " \n",
    " * 'Mean': Contains the mean of the feature values\n",
    " \n",
    " * '50th': Contains the median of the feature values\n",
    "            \n",
    " * '75th': Contains the third quartile (75%) of the feature values\n",
    " \n",
    " * 'Max': Contains the maximum value of the feature,\n",
    "            \n",
    " * 'Std. Dev': Contains the standard deviation of the feature\n",
    " \n",
    "In addition to the values above, you should identify the number of upper and lower outliers using the $val < Q1-1.5IQR$ and $val > Q3+1.5IQR$ outlier identification method ($IRQ$ is the inter quartile range or the distance between $Q1$ and $Q3$). These added features should be called `Outlier Count Low` and `Outliers Count High` respectively.\n",
    "\n",
    "\n",
    " \n",
    " Some useful functions for this can be found at:\n",
    " \n",
    " * [pyspark.sql.functions.percentile](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.percentile.html#pyspark.sql.functions.percentile)\n",
    " \n",
    " * [pyspark.sql.functions.isnan](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.isnan.html#pyspark.sql.functions.isnan)\n",
    " \n",
    " * [pyspark.sql.functions.mean](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.mean.html)\n",
    " \n",
    " * [pyspark.sql.functions.std](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.std.html#pyspark.sql.functions.std)\n",
    "\n",
    " * For more functions go to [pyspark.sql.functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d38f6-7db9-4b6e-a686-2a0db9332029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place your code here\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "def data_quality_report(df, attribute):\n",
    "    quantiles = df.approxQuantile(attribute, [0.25, 0.5, 0.75], 0)\n",
    "    Q1, Q3 = quantiles[0], quantiles[2]\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    outliers_low = df.filter(col(attribute) < Q1 - 1.5 * IQR).count()\n",
    "    outliers_high = df.filter(col(attribute) > Q3 + 1.5 * IQR).count()\n",
    "\n",
    "    report = df.select(\n",
    "        count(col(attribute)).alias('Non-null Count'),\n",
    "        sum(col(attribute).isNull().cast('int')).alias('Null Count'),\n",
    "        min(col(attribute)).alias('Min'),\n",
    "        expr(f'percentile_approx({attribute}, 0.25)').alias('25th'),\n",
    "        expr(f'percentile_approx({attribute}, 0.5)').alias('50th'),\n",
    "        expr(f'percentile_approx({attribute}, 0.75)').alias('75th'),\n",
    "        max(col(attribute)).alias('Max'),\n",
    "        stddev(col(attribute)).alias('std. Dev')\n",
    "    ).withColumn('Feature Name', expr(f\"'{attribute}'\")) \\\n",
    "     .withColumn('Cardinality', df.select(attribute).distinct().count()) \\\n",
    "     .withColumn('Outlier Count Low', expr(f\"{outliers_low}\")) \\\n",
    "     .withColumn('Outlier Count High', expr(f\"{outliers_high}\"))\n",
    "\n",
    "    return report.toPandas()\n",
    "\n",
    "attribute = 'name'\n",
    "report = data_quality_report(abt, attribute)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004920d4-2915-4423-9d67-989ed9f28db0",
   "metadata": {},
   "source": [
    "### Q2 (20 points)\n",
    "Using what you produced to answer Q1, you should now write a function to construct the data quality report for all of the numerical features of our dataset.  You should loop over all of the features in the analytics base table represented by the input feature dataset files from partition 1, with the exception of the first column (this is the index column if you read the file correctly), and the `id`, `lab`, `st`, and `et` columns.  \n",
    "\n",
    "Your output from this function will be a DataFrame that has 1 row for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7716c1f5-6999-4a3d-8481-8887e2a7b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place your code here\n",
    "def construct_data_quality_report(df):\n",
    "    ft = [c for c in df.columns if c not in ['_c0', 'id', 'lab', 'st', 'et']]\n",
    "    report = pd.DataFrame()\n",
    "    for ft in ft:\n",
    "        ft_report = data_quality_report(df, ft)\n",
    "        report = report.append(ft_report)\n",
    "        return report.reset_index(drop=True)\n",
    "report= construct_data_quality_report(abt)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102b228-431f-4387-9681-15f8ee55113f",
   "metadata": {},
   "source": [
    "### Q3 (20 points)\n",
    "#### Drop features with improper cardinality:\n",
    "Using the quality report summary table that is returned from the function you wrote for Q2, we are now going to investigate our data. For this, you should use the table returned for the [Full Partition 1 feature dataset](http://dmlab.cs.gsu.edu/solar/data/partition1ExtractedFeatures.csv) and not the toy dataset I provided for testing.\n",
    "\n",
    "Since we are using real valued features, a majority of them shall have a cardinality close to the sample count. So, for this question, you are to write a function that takes in the summary table and the input dataset DataFrame, and drops the feature that have a cardinality less than 10. This feature should be dropped from both the data quality report summary table and from the actual input dataset Spark DataFrame.\n",
    "\n",
    "A useful method for this operation on the summary table is:\n",
    "\n",
    "* [pandas.DataFrame.drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) (Make sure to use the inplace option otherwise it returns a copy, that way you don't need to return a copy of the summary table it just edits the original)\n",
    "\n",
    "* For the dataset, you will need to return a new DataFrame as they are immutable and the drop operation reutrns a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef102bab-006f-44cf-9fb6-1ab087c95d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place your code here\n",
    "def drop_low_cardinality_features(report, df):\n",
    "    low_cardinality_features = report[report['Cardinality'] < 10]['Feature Name'].values\n",
    "    report.drop(report[report['Feature Name'].isin(low_cardinality_features)].index, inplace=True)\n",
    "    for ft in low_cardinality_features:\n",
    "        df = df.drop(ft)\n",
    "    return df\n",
    "df_new = drop_low_cardinality_features(report, abt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8e5fd0-a985-40c3-9ce1-29a8ff0e7884",
   "metadata": {},
   "source": [
    "### Q4 (20 points)\n",
    "#### Drop features with excessive NaN\n",
    "\n",
    "Again, using the quality report summary table that is returned from the function you wrote for Q2, we are going to continue investigating our data. For this, you should still be using the table returned for the [Full Partition 1 feature dataset](http://dmlab.cs.gsu.edu/solar/data/partition1ExtractedFeatures.csv) and not the toy dataset I provided for testing.\n",
    "\n",
    "Like the features that were dropped for Q3, some of the extracted features don't work on all of the variates of the input multi-variate time series samples very well.  So, some of these features return an excessive number of `NaN` values.  These are not verry useful features, so we want to get rid of them before we continue. To do this, you are to write a function that takes in the summary table and the input dataset DataFrame, and drops the features that have **more than 1%** of the entries as null/nan values. Again, these features should be dropped from both the data quality report summary table and from the actual input dataset Spark DataFrame.\n",
    "\n",
    "As in Q3, a useful method for this operation is:\n",
    "\n",
    "* [pandas.DataFrame.drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) (Make sure to use the inplace option otherwise it returns a copy)\n",
    "  \n",
    "* For the dataset, you will need to return a new DataFrame as they are immutable and the drop operation reutrns a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7972c-8cc1-4fac-843e-2bc5e49a383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place your code here\n",
    "def drop_NaN_ft(report, df):\n",
    "    total_count = df.count()\n",
    "    NaN_ft = report[report['Null Count'] > 0.01 * total_count]['Feature Name'].values\n",
    "    report.drop(report[report['Feature Name'].isin(NaN_ft)].index, inplace=True)\n",
    "    for ft in NaN_ft:\n",
    "        df = df.drop(ft)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef27684-f80f-415d-b859-29c5d0af89f0",
   "metadata": {},
   "source": [
    "### Q5 (20 points)\n",
    "#### Add docstring to your functions\n",
    "\n",
    "Let's revisit our programming skill while learning some fundamental data science operations. \n",
    "\n",
    "Your code is only as valuable as its reusability. Without understandable and legible documentation (which makes maintainability and reusability possible) nobody would like to use your code, let alone to pay for it. ;)\n",
    "\n",
    "If you want to know more about the value of documentation, read [this article](https://www.freecodecamp.org/news/why-documentation-matters-and-why-you-should-include-it-in-your-code-41ef62dd5c2f/). There are even conferences on this topic; see [this website](https://www.writethedocs.org/guide/writing/beginners-guide-to-docs/).\n",
    "\n",
    "In Python, the documentation that is embedded in the code is called **docstring**. In the example below, the \"string\" wrapped in triple quotes is there to tell us all about this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330abaf-052a-4a5f-abc4-3dd1611ceb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanmean(a, axis=None):\n",
    "    \"\"\"\n",
    "    Compute the arithmetic mean along the specified axis, ignoring NaNs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        Array containing numbers whose mean is desired. If `a` is not an\n",
    "        array, a conversion is attempted.\n",
    "    axis : {int, tuple of int, None}, optional\n",
    "        Axis or axes along which the means are computed. The default is to compute\n",
    "        the mean of the flattened array.\n",
    "    \"\"\"\n",
    "    # some magic happens here that we don't care about.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe364e-8365-418e-bd34-b8ef0e948013",
   "metadata": {},
   "source": [
    "Note that this is not just a *comment*. If you execute `nanmean` and then call it (as if you want to use it), you can hit `shift+Tab` while your cursor is on the function name, and see how the docstring gets compiled and then pops up. This allows other users to see our description even when they don't have access to our source code. Try it! You can do this with other NumPy and Pandas functions/methods that you've been using.\n",
    "\n",
    "The above example is a simplified version of the method `nanmean` copied from the NumPy library ([here](https://github.com/numpy/numpy/blob/v1.21.0/numpy/lib/nanfunctions.py#L862-L957)). Feel free to check out their complete docstrings.\n",
    "\n",
    "\n",
    "Your last task is to provide docstrings for the 4 methods you've implemented. Simply go back to those cells and modify your functions. Feel free to use the text provided to you (in the assignment descriptions) to enrich your docstrings. Keep in mind that your docstring needs (1) a general description, (2) a short description for each input, and (3) a short description for the output.\n",
    "\n",
    "How to check your docstring? Hit `shift+Tab` and see if the pop-up message is correctly compiled, and make sure your description answers all the questions about your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849fc501-16d8-4bc1-a786-7093dd7a4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "def data_quality_report(df, attribute):\n",
    "    \"\"\"\n",
    "    Generates a data quality report for a specific numerical attribute in a pandas DataFrame.\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input pandas DataFrame containing the dataset.\n",
    "    - attribute (str): The name of the numerical attribute column for which the report is generated.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Data quality report for the specified numerical attribute.\n",
    "    \"\"\"\n",
    "    quantiles = df.approxQuantile(attribute, [0.25, 0.5, 0.75], 0)\n",
    "    Q1, Q3 = quantiles[0], quantiles[2]\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    outliers_low = df.filter(col(attribute) < Q1 - 1.5 * IQR).count()\n",
    "    outliers_high = df.filter(col(attribute) > Q3 + 1.5 * IQR).count()\n",
    "\n",
    "    report = df.select(\n",
    "        count(col(attribute)).alias('Non-null Count'),\n",
    "        sum(col(attribute).isNull().cast('int')).alias('Null Count'),\n",
    "        min(col(attribute)).alias('Min'),\n",
    "        expr(f'percentile_approx({attribute}, 0.25)').alias('25th'),\n",
    "        expr(f'percentile_approx({attribute}, 0.5)').alias('50th'),\n",
    "        expr(f'percentile_approx({attribute}, 0.75)').alias('75th'),\n",
    "        max(col(attribute)).alias('Max'),\n",
    "        stddev(col(attribute)).alias('std. Dev')\n",
    "    ).withColumn('Feature Name', expr(f\"'{attribute}'\")) \\\n",
    "     .withColumn('Cardinality', df.select(attribute).distinct().count()) \\\n",
    "     .withColumn('Outlier Count Low', expr(f\"{outliers_low}\")) \\\n",
    "     .withColumn('Outlier Count High', expr(f\"{outliers_high}\"))\n",
    "\n",
    "    return report.toPandas()\n",
    "\n",
    "attribute = 'name'\n",
    "report = data_quality_report(abt, attribute)\n",
    "print(report)\n",
    "\n",
    "def construct_data_quality_report(df):\n",
    "    \"\"\"\n",
    "    Constructs a comprehensive data quality report for all numerical features in a pandas DataFrame.\n",
    "     Parameters:\n",
    "    - df (pd.DataFrame): The input pandas DataFrame containing the dataset.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Summary data quality report for all numerical features in the dataset.\n",
    "    \"\"\"\n",
    "     ft = [c for c in df.columns if c not in ['_c0', 'id', 'lab', 'st', 'et']]\n",
    "    report = pd.DataFrame()\n",
    "    for ft in ft:\n",
    "        ft_report = data_quality_report(df, ft)\n",
    "        report = report.append(ft_report)\n",
    "        return report.reset_index(drop=True)\n",
    "report= construct_data_quality_report(abt)\n",
    "print(report)\n",
    "\n",
    "\n",
    "def drop_low_cardinality_features(report, df):\n",
    "    \"\"\"\n",
    "    Drops features with a low cardinality from both the data quality report summary table\n",
    "    and the input pandas DataFrame.\n",
    "    Parameters:\n",
    "    - report (pd.DataFrame): The data quality report summary table.\n",
    "    - df (pd.DataFrame): The input pandas DataFrame containing the dataset.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Updated data quality report summary table and input dataset DataFrame.\n",
    "    \"\"\"\n",
    "    low_cardinality_features = report[report['Cardinality'] < 10]['Feature Name'].values\n",
    "    report.drop(report[report['Feature Name'].isin(low_cardinality_features)].index, inplace=True)\n",
    "    for ft in low_cardinality_features:\n",
    "        df = df.drop(ft)\n",
    "    return df\n",
    "df_new = drop_low_cardinality_features(report, abt)\n",
    "\n",
    "def drop_NaN_ft(report, df, nan_threshold=0.01):\n",
    "    \"\"\"\n",
    "    Drops features with a high percentage of nan values from both the data quality\n",
    "    report summary table and the input pandas DataFrame.\n",
    "    Parameters:\n",
    "    - report (pd.DataFrame): The data quality report summary table.\n",
    "    - df (pd.DataFrame): The input pandas DataFrame containing the dataset.\n",
    "    - nan_threshold (float): The threshold for the percentage of null/nan values.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Updated data quality report summary table and input dataset DataFrame.\n",
    "    \"\"\"\n",
    "    total_count = df.count()\n",
    "    NaN_ft = report[report['Null Count'] > 0.01 * total_count]['Feature Name'].values\n",
    "    report.drop(report[report['Feature Name'].isin(NaN_ft)].index, inplace=True)\n",
    "    for ft in NaN_ft:\n",
    "        df = df.drop(ft)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
